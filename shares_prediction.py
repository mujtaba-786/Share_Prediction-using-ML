# -*- coding: utf-8 -*-
"""Shares_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tyYn5i-gUwyqtLWlKJN6fz7F_vJzvF-g
"""

from google.colab import files
file = files.upload()

!unzip 'Project 4 Shares prediction-20201204T074439Z-001 (1).zip'

# import required modules and libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('Project 4 Shares prediction/train.csv')

df = data.copy()





"""# **EXPLORATORY DATA ANALYSIS**"""

df.head()

df.tail()

df.shape

df.columns

df.info()

df.isna().sum()

min(df[' shares']) , max(df[' shares'])

sns.distplot(df[' shares'])



"""# **DATA CORRELATION**"""



df.corr()

sns.heatmap(df.corr())

# lets plot correlation plot in another form as heatmap is not clear to conclude feature importance

plt.figure(figsize=(14,6))
df.drop(' shares', axis=1).corrwith(df[' shares']).plot(kind = 'bar', grid = True,title = "Correlation with traffic_volume")



pip install catboost





"""# TRAINING AND TESTING THE DATA USING ML MODELS"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor
from catboost import CatBoostRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

X=df.drop([' shares'],axis=1)
X.head()

y=df[' shares']
y.head()

x_train, x_test , y_train , y_test = train_test_split(X,y,random_state=40)

from sklearn.preprocessing import StandardScaler 

sc = StandardScaler() 
  
x_train = sc.fit_transform(x_train) 
x_test = sc.transform(x_test)

from sklearn.decomposition import PCA 
  
pca = PCA() 
  
x_train = pca.fit_transform(x_train) 
x_test = pca.transform(x_test)

# LinearRegression

model = LinearRegression()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

# KNeighborsRegressor

model = KNeighborsRegressor()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

# model = RandomForestRegressor()

model = RandomForestRegressor()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

# GradientBoostingRegressor

model = GradientBoostingRegressor()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

# CatBoostRegressor

model = CatBoostRegressor()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

# SVR

model = SVR()
model.fit(x_train, y_train)
pred=model.predict(x_test)
mean_squared_error(y_test,pred,squared=False)

"""# **We will choose LinearRegresion model as it is giving much better rmse as compared to other ML models**"""



"""# SHARES PREDICTION ON TEST DATA"""

test = pd.read_csv('Project 4 Shares prediction/test.csv')

df=test.copy()

df.head()

df.shape

df.info()

df.isna().sum()

sc = StandardScaler() 
  
df = sc.fit_transform(df)

pca = PCA() 
  
df = pca.fit_transform(df)

predict=model.predict(df)

predict

min(predict) , max(predict)

len(predict)

# save and download csv file
from IPython.display import HTML
import base64

def create_download_link( df, title = "Download CSV file", filename = "data.csv"):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}" target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)

index=[i for i in range(11894)]
sub=pd.DataFrame({'instance_id':index, 'share':predict})

create_download_link(sub)

